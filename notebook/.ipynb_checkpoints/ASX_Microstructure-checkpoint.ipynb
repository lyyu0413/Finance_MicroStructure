{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to empirical market microstructure in Python\n",
    "\n",
    "Created and modified by LYYU0413 from notebook previously prepared by [Vincent Grégoire](http://www.vincentgregoire.com), Department of Finance, The University of Melbourne. \n",
    "\n",
    "\n",
    "\n",
    "**Outline**:\n",
    "\n",
    "- Load trades and quotes\n",
    "- Parsing timestamps (and convert from UTC)\n",
    "- Cleaning, forward filling quotes\n",
    "- Realized spread (merging asof)\n",
    "- Time-weighted depth\n",
    "- Plot something\n",
    "- Summarize data at the stock/day level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data requested from TRTH is in a file named \"ASX20_HalfMarch2017.csv.gz\". First, let's get a sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>BID</th>\n",
       "      <th>OFR</th>\n",
       "      <th>BIDSIZ</th>\n",
       "      <th>OFRSIZ</th>\n",
       "      <th>MODE</th>\n",
       "      <th>EX</th>\n",
       "      <th>MMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>8:36:56</td>\n",
       "      <td>25.38</td>\n",
       "      <td>25.32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>8:37:05</td>\n",
       "      <td>25.38</td>\n",
       "      <td>25.32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>8:37:21</td>\n",
       "      <td>25.38</td>\n",
       "      <td>25.41</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>8:37:21</td>\n",
       "      <td>25.36</td>\n",
       "      <td>25.42</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>20050310</td>\n",
       "      <td>8:37:21</td>\n",
       "      <td>25.40</td>\n",
       "      <td>25.42</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SYMBOL      DATE     TIME    BID    OFR  BIDSIZ  OFRSIZ  MODE EX  MMID\n",
       "0    MSFT  20050310  7:30:00  25.30  25.32       1       1    12  T   NaN\n",
       "1    MSFT  20050310  7:30:00  25.30  25.32       1       1    12  T   NaN\n",
       "2    MSFT  20050310  7:30:00  25.30  25.32       1       1    12  T   NaN\n",
       "3    MSFT  20050310  7:30:00  25.30  25.32       1       1    12  T   NaN\n",
       "4    MSFT  20050310  7:30:00  25.30  25.32       1       1    12  T   NaN\n",
       "..    ...       ...      ...    ...    ...     ...     ...   ... ..   ...\n",
       "95   MSFT  20050310  8:36:56  25.38  25.32       5       1    12  T   NaN\n",
       "96   MSFT  20050310  8:37:05  25.38  25.32       4       1    12  T   NaN\n",
       "97   MSFT  20050310  8:37:21  25.38  25.41       9      25    12  P   NaN\n",
       "98   MSFT  20050310  8:37:21  25.36  25.42       4      29    12  C   NaN\n",
       "99   MSFT  20050310  8:37:21  25.40  25.42      10      29    12  C   NaN\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/MSFT.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we won't use the TRTH timestamps (we'll use exchange timestamps). It will also be more practictal to split trades and quotes in different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['#RIC', 'Date[L]','Quote Time', 'Bid Price',  'Ask Price','Bid Size',\n",
    "       'Ask Size',\"Mode\", 'Exch Time', 'Qualifiers'] #  'Type' 'Price', 'Volume', \n",
    "df = pd.read_csv('MSFT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotes = df[['#RIC', 'Date[L]','Bid Price', 'Bid Size',\n",
    "                                      'Ask Price', 'Ask Size', 'Quote Time']].copy()\n",
    "df_quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trades = df[['#RIC', 'Date[L]', 'Price', 'Volume', 'Qualifiers', 'Exch Time']].copy()\n",
    "# df_trades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse dates and timestamps, we'll use a simple trick that saves time by assuming a lot of dates and times are the same. We parse date and time separately since there is much more redundancy in dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_simple_date(d):\n",
    "    return datetime.strptime(d, '%m/%d/%Y')\n",
    "\n",
    "def parse_simple_time(t):\n",
    "    # The data is up to the second precision.\n",
    "    return timedelta(hours=int(t[0:2]), minutes=int(t[3:5]),\n",
    "                     seconds=int(t[6:8]))\n",
    "\n",
    "def fast_date_parse(df, col, date_parser=parse_simple_date):\n",
    "    dt = pd.DataFrame(df[col].unique())\n",
    "    dt.columns = [col + '_tmp']\n",
    "    dt[col] = dt[col + '_tmp'].apply(date_parser)\n",
    "    date_dict = dt.set_index(col + '_tmp').to_dict()\n",
    "    df[col] = df[col].map(date_dict[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To join dates and times, we need to account for time zone. Dates are local dates (Sydney),\n",
    "# but times are in UTC.\n",
    "df_trades = fast_date_parse(df_trades, 'Exch Time', parse_simple_time)\n",
    "df_trades = fast_date_parse(df_trades, 'Date[L]')\n",
    "df_trades['Timestamp'] = (df_trades['Date[L]'].dt.tz_localize('UTC').dt.tz_convert('Australia/Sydney') +\n",
    "                          df_trades['Exch Time'])\n",
    "sel = (df_trades.Timestamp.dt.date != df_trades['Date[L]'].dt.date)\n",
    "df_trades.loc[sel, 'Timestamp'] = df_trades.loc[sel, 'Timestamp'] - timedelta(days=1)\n",
    "df_trades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_quotes = fast_date_parse(df_quotes, 'Quote Time', parse_simple_time)\n",
    "df_quotes = fast_date_parse(df_quotes, 'Date[L]')\n",
    "df_quotes['Timestamp'] = (df_quotes['Date[L]'].dt.tz_localize('UTC').dt.tz_convert('Australia/Sydney') +\n",
    "                          df_quotes['Quote Time'])\n",
    "sel = (df_quotes.Timestamp.dt.date != df_quotes['Date[L]'].dt.date)\n",
    "df_quotes.loc[sel, 'Timestamp'] = df_quotes.loc[sel, 'Timestamp'] - timedelta(days=1)\n",
    "df_quotes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, quotes get updated only one side at a time, so we need to fill forward the quotes.\n",
    "\n",
    "We will first do the processing on one day only. It will be easier to see, and then we can write a function\n",
    "with our code to loop over every day in the sample. This is usually a good approach; when the processing is split into logical elements (i.e. stock or day) it is easier to write and to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = df_quotes[df_quotes['Date[L]'] == datetime(2017, 3, 1)].copy()\n",
    "trades = df_trades[df_trades['Date[L]'] == datetime(2017, 3, 1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quotes_cols = ['Bid Price', 'Bid Size', 'Ask Price', 'Ask Size']\n",
    "quotes[quotes_cols] = quotes.groupby(['#RIC'])[quotes_cols].fillna(method='ffill')\n",
    "# Missing values implie no depth\n",
    "quotes[['Bid Size', 'Ask Size']] = quotes[['Bid Size', 'Ask Size']].fillna(0.0)\n",
    "quotes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes['MidQuote'] = (quotes['Bid Price'] + quotes['Ask Price'])/2.0\n",
    "quotes['DepthOnTop'] = (quotes['Bid Size'] + quotes['Ask Size'])/2.0\n",
    "quotes['Spread'] = quotes['Ask Price'] - quotes['Bid Price']\n",
    "quotes['RelSpread'] = quotes['Spread']/quotes['MidQuote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades['Value'] = trades['Price'] * trades['Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to focus on continuous trading.\n",
    "\n",
    "We can look at trading hours on [ASX's website](http://www.asx.com.au/about/trading-hours.htm).\n",
    "\n",
    "By 10:10 am, all stocks should be open, and they all stop at 4pm for an auction about 10 minutes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will focus on continuous trading. \n",
    "start_time = time(hour=10, minute=10)\n",
    "end_time = time(hour=16, minute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ((trades.Timestamp.dt.time > start_time) &\n",
    "       (trades.Timestamp.dt.time < end_time))\n",
    "\n",
    "trades_open = trades[sel].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ((trades.Timestamp.dt.time > start_time) &\n",
    "       (trades.Timestamp.dt.time < end_time))\n",
    "\n",
    "trades_open = trades[sel].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_open = trades_open.sort_values(['Timestamp', '#RIC'])\n",
    "quotes = quotes.sort_values(['Timestamp', '#RIC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spreads\n",
    "\n",
    "Two common measures for the cost of trading are the effective spread and the realized spread.\n",
    "\n",
    "The definition for each of them is the following:\n",
    "\n",
    "### Effective spread\n",
    "\n",
    "Buy market order: $2\\times (p_t - m_t)$\n",
    "\n",
    "Sell market order: $2\\times (m_t - p_t)$\n",
    "\n",
    "where $p_t$ is the price for the transaction at time $t$, and $m_t$ is the mid quote at time $t-\\varepsilon$ (just before the trade).\n",
    "\n",
    "\n",
    "### Realized spread\n",
    "\n",
    "Buy market order: $2\\times (p_t - m_{t+\\Delta})$\n",
    "\n",
    "Sell market order: $2\\times (m_{t+\\Delta} - p_t)$\n",
    "\n",
    "where $p_t$ is the price for the transaction at time $t$, and $m_{t+\\Delta}$ is the mid quote at time ${t+\\Delta}$. A common value for $\\Delta$ is 5 minutes, so we'll use that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, we need to merge trades and quotes at the right time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_open['TS_5min'] = trades_open['Timestamp'] + timedelta(minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged = pd.merge_asof(trades_open,\n",
    "                           quotes[['#RIC', 'Timestamp', 'Bid Price', 'Ask Price', 'MidQuote']],\n",
    "                           on='Timestamp', by='#RIC', allow_exact_matches=False)\n",
    "\n",
    "taq_merged = pd.merge_asof(taq_merged,\n",
    "                           quotes[['#RIC', 'Timestamp', 'Bid Price', 'Ask Price', 'MidQuote']],\n",
    "                           left_on='TS_5min', right_on='Timestamp',\n",
    "                           by='#RIC', suffixes=('', '_5min'),\n",
    "                           allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to \"sign\" the trades, figure out if it's a buy or a sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged['Sign'] = ''\n",
    "taq_merged.loc[taq_merged.Price == taq_merged['Bid Price'], 'Sign'] = 'S'\n",
    "taq_merged.loc[taq_merged.Price == taq_merged['Ask Price'], 'Sign'] = 'B'\n",
    "taq_merged.loc[taq_merged.Price == taq_merged['MidQuote'], 'Sign'] = 'C' # Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective Spread\n",
    "\n",
    "Buy market order: $2\\times (p_t - m_t)$\n",
    "\n",
    "Sell market order: $2\\times (m_t - p_t)$\n",
    "\n",
    "where $p_t$ is the price for the transaction at time $t$, and $m_t$ is the mid quote at time $t-\\varepsilon$ (just before the trade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable for every obs\n",
    "taq_merged['Effective Spread'] = np.nan\n",
    "b_sel = taq_merged.Sign == 'B'\n",
    "taq_merged.loc[b_sel, 'Effective Spread'] = 2*(taq_merged.loc[b_sel, 'Price'] -\n",
    "                                               taq_merged.loc[b_sel, 'MidQuote'])\n",
    "s_sel = taq_merged.Sign == 'S'\n",
    "taq_merged.loc[s_sel, 'Effective Spread'] = 2*(taq_merged.loc[s_sel, 'MidQuote'] -\n",
    "                                               taq_merged.loc[s_sel, 'Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realized spread\n",
    "\n",
    "Buy market order: $2\\times (p_t - m_{t+\\Delta})$\n",
    "\n",
    "Sell market order: $2\\times (m_{t+\\Delta} - p_t)$\n",
    "\n",
    "where $p_t$ is the price for the transaction at time $t$, and $m_{t+\\Delta}$ is the mid quote at time ${t+\\Delta}$. We use $\\Delta=$5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable for every obs\n",
    "taq_merged['Realized Spread'] = np.nan\n",
    "b_sel = taq_merged.Sign == 'B'\n",
    "taq_merged.loc[b_sel, 'Realized Spread'] = 2*(taq_merged.loc[b_sel, 'Price'] -\n",
    "                                              taq_merged.loc[b_sel, 'MidQuote_5min'])\n",
    "s_sel = taq_merged.Sign == 'S'\n",
    "taq_merged.loc[s_sel, 'Realized Spread'] = 2*(taq_merged.loc[s_sel, 'MidQuote_5min'] -\n",
    "                                              taq_merged.loc[s_sel, 'Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: here we might choose to do something special for trades in the last 5 minutes, such as recomputing realized spread using the closing auction price instead of the midquote. We won't do it, meaning we're using the prevailing mid-quote at market close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price impact\n",
    "\n",
    "The realized spread is a measure of price impact, i.e., it measures how trades move prices. If prices move in the direction of the trade, realized spread becomes smaller and possibly negative. We might expect that price impact is related to trade size. To make everything comparable, we need to make the measures \"relative\" (i.e., in %) to something, either price or mid-quote. We use the prevailing mid-quote at trade time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged['RelEffective Spread'] = taq_merged['Effective Spread'] / taq_merged['MidQuote']\n",
    "taq_merged['RelRealized Spread'] = taq_merged['Realized Spread'] / taq_merged['MidQuote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged.plot.scatter(x='Value', y='RelRealized Spread');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have a few outliers, so it's hard to see what is going on. One way around this issue is to group trades in value deciles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taq_merged['Value_q10'] = pd.qcut(taq_merged['Value'], q=10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_q10_mean = taq_merged.groupby('Value_q10')[['RelEffective Spread', 'RelRealized Spread', \n",
    "                                                'Effective Spread', 'Realized Spread']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_q10_mean[['RelEffective Spread', 'RelRealized Spread']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_q10_mean[['Effective Spread', 'Realized Spread']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the average value for each stock/day, we can groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd_mean = taq_merged.groupby(['#RIC', 'Date[L]'])[['RelEffective Spread', 'RelRealized Spread', \n",
    "                               'Effective Spread', 'Realized Spread']].mean()\n",
    "spd_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get trade value-weighted average instead, it's not much harder.\n",
    "cols = ['RelEffective Spread', 'RelRealized Spread',\n",
    "        'Effective Spread', 'Realized Spread']\n",
    "for c in cols:\n",
    "    taq_merged[c + '_VW'] = taq_merged[c] * taq_merged['Value']\n",
    "\n",
    "for c in cols:\n",
    "    spd_mean[c + '_VW'] = (taq_merged.groupby(['#RIC', 'Date[L]'])[c + '_VW'].sum() /\n",
    "                          taq_merged.groupby(['#RIC', 'Date[L]'])['Value'].sum())\n",
    "spd_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-weighted measures\n",
    "\n",
    "Another couple of interesting measures are the time-weighted spread and depth, which give an idea of the liquidity available. Since these are time-weighted, we take the average value, weighted by the duration of the spread or available depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to compute the time interval. We cannot use diff() since we want the difference\n",
    "# between the next timestmap (when a new quote/depth is set) and the current timestamp.\n",
    "quotes['time_d'] = (quotes.groupby('#RIC')['Quote Time'].shift(-1) - quotes['Quote Time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we do as before, using 'time_d' instead of Value for our weights.\n",
    "cols = ['Spread', 'RelSpread', 'DepthOnTop']\n",
    "for c in cols:\n",
    "    quotes[c + '_TW'] = quotes[c] * quotes['time_d']\n",
    "\n",
    "tw_mean = quotes.groupby(['#RIC', 'Date[L]'])[[c + '_TW' for c in cols]].sum()\n",
    "    \n",
    "for c in cols:\n",
    "    tw_mean[c + '_TW'] = (tw_mean[c + '_TW'] /\n",
    "                          quotes.groupby(['#RIC', 'Date[L]'])['time_d'].sum())\n",
    "tw_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can merge our two datasets\n",
    "\n",
    "merged = pd.merge(spd_mean, tw_mean, left_index=True, right_index=True)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Now that we have done all of this for one day, package as a function to loop over every day in the sample (without the plots) \n",
    "and then merge to get a complete stock/day panel, and export it to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
